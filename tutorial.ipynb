{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52240e604bec8672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:52:53.680525Z",
     "start_time": "2024-12-19T16:52:53.432881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\n",
      "['Fraud.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "directory = kagglehub.dataset_download(\"chitwanmanchanda/fraudulent-transactions-data\")\n",
    "path = os.path.join(directory, \"Fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea01f9df90853a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:50:43.935473Z",
     "start_time": "2024-12-19T16:50:43.504374Z"
    }
   },
   "outputs": [],
   "source": [
    "from daft.daft import connect_start\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# start Daft Connect (spark-connect compatible server)\n",
    "handle = connect_start(\"sc://0.0.0.0:15003\")\n",
    "\n",
    "# create a Spark Connect client connected to the Daft Connect server\n",
    "spark = SparkSession.builder.remote(\"sc://localhost:15003\").appName(\"DaftPySparkExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1cb80997b3f915",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:50:46.268563Z",
     "start_time": "2024-12-19T16:50:46.216987Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewgazelka/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—¡ï¸ ğŸŸ Limit: 00:00 0 rows received, 0 rows emitted\n",
      "ğŸ—¡ï¸ ğŸŸ InMemory: 00:00 0 rows emitted\u001b[A\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â•®          \n",
      "â”‚ _1    â”† _2   â”† _3     â”† _4   â”† _5    â”‚\n",
      "â”‚ ---   â”† ---  â”† ---    â”† ---  â”† ---   â”‚\n",
      "â”‚ Int64 â”† Utf8 â”† Utf8   â”† Utf8 â”† Int64 â”‚\n",
      "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2021  â”† test â”† Albany â”† M    â”† 42    â”‚\n",
      "â•°â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    }
   ],
   "source": [
    "data = [[2021, \"test\", \"Albany\", \"M\", 42]]\n",
    "columns = [\"Year\", \"First_Name\", \"County\", \"Sex\", \"Count\"]\n",
    "\n",
    "df1 = spark.createDataFrame(data, schema=\"Year int, First_Name STRING, County STRING, Sex STRING, Count int\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f471d89dedf29b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:54:00.003220Z",
     "start_time": "2024-12-19T16:53:59.848698Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring is_streaming: false\n",
      "Ignoring schema: \"\"; not yet implemented\n",
      "Ignoring options: {\"inferSchema\": \"True\", \"header\": \"True\", \"sep\": \",\"}; not yet implemented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—¡ï¸ ğŸŸ Limit: 00:00 0 rows received, 0 rows emitted\n",
      "ğŸ—¡ï¸ ğŸŸ ScanTask: 00:00 0 rows emitted\u001b[A\n",
      "â•­â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
      "â”‚ step  â”† type     â”† amount    â”†      â€¦     â”† newbalanceDest â”† isFraud â”† isFlaggedFraud â”‚\n",
      "â”‚ ---   â”† ---      â”† ---       â”†            â”† ---            â”† ---     â”† ---            â”‚\n",
      "â”‚ Int64 â”† Utf8     â”† Float64   â”† (5 hidden) â”† Float64        â”† Int64   â”† Int64          â”‚\n",
      "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 1     â”† PAYMENT  â”† 9839.64   â”† â€¦          â”† 0              â”† 0       â”† 0              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ 1     â”† PAYMENT  â”† 1864.28   â”† â€¦          â”† 0              â”† 0       â”† 0              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ 1     â”† TRANSFER â”† 181       â”† â€¦          â”† 0              â”† 1       â”† 0              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ 1     â”† CASH_OUT â”† 181       â”† â€¦          â”† 0              â”† 1       â”† 0              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ 1     â”† PAYMENT  â”† 11668.14  â”† â€¦          â”† 0              â”† 0       â”† 0              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ â€¦     â”† â€¦        â”† â€¦         â”† â€¦          â”† â€¦              â”† â€¦       â”† â€¦              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ 1     â”† CASH_OUT â”† 229133.94 â”† â€¦          â”† 51513.44       â”† 0       â”† 0              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ 1     â”† PAYMENT  â”† 1563.82   â”† â€¦          â”† 0              â”† 0       â”† 0              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ 1     â”† PAYMENT  â”† 1157.86   â”† â€¦          â”† 0              â”† 0       â”† 0              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ 1     â”† PAYMENT  â”† 671.64    â”† â€¦          â”† 0              â”† 0       â”† 0              â”‚\n",
      "â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\n",
      "â”‚ 1     â”† TRANSFER â”† 215310.3  â”† â€¦          â”† 0              â”† 0       â”† 0              â”‚\n",
      "â•°â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(path, header=True, inferSchema=True, sep=\",\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d8765edba4d381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:54:10.340750Z",
     "start_time": "2024-12-19T16:54:10.205934Z"
    }
   },
   "outputs": [
    {
     "ename": "SparkConnectGrpcException",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Error in Daft server: Failed to show string\n\nCaused by:\n    Unsupported relation type: WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(14), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(13), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(12), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(11), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(10), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(9), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(8), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(6), origin: None }), rel_type: Some(Read(Read { is_streaming: false, read_type: Some(DataSource(DataSource { format: Some(\"csv\"), schema: Some(\"\"), options: {\"header\": \"True\", \"sep\": \",\", \"inferSchema\": \"True\"}, paths: [\"/Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\"], predicates: [] })) })) }), rename_columns_map: {\"oldbalanceOrg\": \"oldBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"newbalanceOrig\": \"newBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceDest\": \"oldBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"newbalanceDest\": \"newBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceOrg\": \"oldBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"newbalanceOrig\": \"newBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceDest\": \"oldBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"newbalanceDest\": \"newBalanceDest\"}, renames: [] })\n\nLocation:\n    src/daft-connect/src/translation/logical_plan.rs:132:21\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:15003 {grpc_message:\"Error in Daft server: Failed to show string\\n\\nCaused by:\\n    Unsupported relation type: WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(14), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(13), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(12), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(11), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(10), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(9), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(8), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(6), origin: None }), rel_type: Some(Read(Read { is_streaming: false, read_type: Some(DataSource(DataSource { format: Some(\\\"csv\\\"), schema: Some(\\\"\\\"), options: {\\\"header\\\": \\\"True\\\", \\\"sep\\\": \\\",\\\", \\\"inferSchema\\\": \\\"True\\\"}, paths: [\\\"/Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\\\"], predicates: [] })) })) }), rename_columns_map: {\\\"oldbalanceOrg\\\": \\\"oldBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceOrig\\\": \\\"newBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceDest\\\": \\\"oldBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceDest\\\": \\\"newBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceOrg\\\": \\\"oldBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceOrig\\\": \\\"newBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceDest\\\": \\\"oldBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceDest\\\": \\\"newBalanceDest\\\"}, renames: [] })\\n\\nLocation:\\n    src/daft-connect/src/translation/logical_plan.rs:132:21\", grpc_status:13, created_time:\"2024-12-19T08:54:10.208962-08:00\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSparkConnectGrpcException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m old_col, new_col \u001b[38;5;129;01min\u001b[39;00m corrected_cols\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumnRenamed(old_col, new_col)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/dataframe.py:996\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 996\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/dataframe.py:753\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    743\u001b[0m             error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    744\u001b[0m             message_parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m             },\n\u001b[1;32m    748\u001b[0m         )\n\u001b[1;32m    750\u001b[0m pdf \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithPlan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mShowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_truncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 753\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pdf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_string\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/dataframe.py:1663\u001b[0m, in \u001b[0;36mDataFrame.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot collect on empty session.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1662\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plan\u001b[38;5;241m.\u001b[39mto_proto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mclient)\n\u001b[0;32m-> 1663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:873\u001b[0m, in \u001b[0;36mSparkConnectClient.to_pandas\u001b[0;34m(self, plan)\u001b[0m\n\u001b[1;32m    869\u001b[0m (self_destruct_conf,) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_config_with_defaults(\n\u001b[1;32m    870\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.sql.execution.arrow.pyspark.selfDestruct.enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    871\u001b[0m )\n\u001b[1;32m    872\u001b[0m self_destruct \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, self_destruct_conf)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 873\u001b[0m table, schema, metrics, observed_metrics, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_and_fetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_destruct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_destruct\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    878\u001b[0m schema \u001b[38;5;241m=\u001b[39m schema \u001b[38;5;129;01mor\u001b[39;00m from_arrow_schema(table\u001b[38;5;241m.\u001b[39mschema, prefer_timestamp_ntz\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1283\u001b[0m, in \u001b[0;36mSparkConnectClient._execute_and_fetch\u001b[0;34m(self, req, self_destruct)\u001b[0m\n\u001b[1;32m   1280\u001b[0m schema: Optional[StructType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m properties: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1283\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_and_fetch_as_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStructType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\n",
      "File \u001b[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1264\u001b[0m, in \u001b[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1262\u001b[0m                     \u001b[38;5;28;01myield from\u001b[39;00m handle_response(b)\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1503\u001b[0m, in \u001b[0;36mSparkConnectClient._handle_error\u001b[0;34m(self, error)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;124;03mHandle errors that occur during RPC calls.\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;124;03mThrows the appropriate internal Python exception.\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, grpc\u001b[38;5;241m.\u001b[39mRpcError):\n\u001b[0;32m-> 1503\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_rpc_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke RPC\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(error) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(error):\n",
      "File \u001b[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1543\u001b[0m, in \u001b[0;36mSparkConnectClient._handle_rpc_error\u001b[0;34m(self, rpc_error)\u001b[0m\n\u001b[1;32m   1541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SparkConnectGrpcException(status\u001b[38;5;241m.\u001b[39mmessage) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SparkConnectGrpcException(\u001b[38;5;28mstr\u001b[39m(rpc_error)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mSparkConnectGrpcException\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Error in Daft server: Failed to show string\n\nCaused by:\n    Unsupported relation type: WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(14), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(13), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(12), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(11), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(10), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(9), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(8), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(6), origin: None }), rel_type: Some(Read(Read { is_streaming: false, read_type: Some(DataSource(DataSource { format: Some(\"csv\"), schema: Some(\"\"), options: {\"header\": \"True\", \"sep\": \",\", \"inferSchema\": \"True\"}, paths: [\"/Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\"], predicates: [] })) })) }), rename_columns_map: {\"oldbalanceOrg\": \"oldBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"newbalanceOrig\": \"newBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceDest\": \"oldBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"newbalanceDest\": \"newBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceOrg\": \"oldBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"newbalanceOrig\": \"newBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceDest\": \"oldBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"newbalanceDest\": \"newBalanceDest\"}, renames: [] })\n\nLocation:\n    src/daft-connect/src/translation/logical_plan.rs:132:21\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:15003 {grpc_message:\"Error in Daft server: Failed to show string\\n\\nCaused by:\\n    Unsupported relation type: WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(14), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(13), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(12), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(11), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(10), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(9), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(8), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(6), origin: None }), rel_type: Some(Read(Read { is_streaming: false, read_type: Some(DataSource(DataSource { format: Some(\\\"csv\\\"), schema: Some(\\\"\\\"), options: {\\\"header\\\": \\\"True\\\", \\\"sep\\\": \\\",\\\", \\\"inferSchema\\\": \\\"True\\\"}, paths: [\\\"/Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\\\"], predicates: [] })) })) }), rename_columns_map: {\\\"oldbalanceOrg\\\": \\\"oldBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceOrig\\\": \\\"newBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceDest\\\": \\\"oldBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceDest\\\": \\\"newBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceOrg\\\": \\\"oldBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceOrig\\\": \\\"newBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceDest\\\": \\\"oldBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceDest\\\": \\\"newBalanceDest\\\"}, renames: [] })\\n\\nLocation:\\n    src/daft-connect/src/translation/logical_plan.rs:132:21\", grpc_status:13, created_time:\"2024-12-19T08:54:10.208962-08:00\"}\"\n>"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "corrected_cols = {\n",
    "    \"oldbalanceOrg\": \"oldBalanceOrig\",\n",
    "    \"newbalanceOrig\": \"newBalanceOrig\",\n",
    "    \"oldbalanceDest\": \"oldBalanceDest\",\n",
    "    \"newbalanceDest\": \"newBalanceDest\",\n",
    "}\n",
    "for old_col, new_col in corrected_cols.items():\n",
    "    df = df.withColumnRenamed(old_col, new_col)\n",
    "\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
