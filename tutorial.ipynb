{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:52:53.680525Z",
     "start_time": "2024-12-19T16:52:53.432881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "directory = kagglehub.dataset_download(\"chitwanmanchanda/fraudulent-transactions-data\")\n",
    "path = os.path.join(directory, \"Fraud.csv\")"
   ],
   "id": "52240e604bec8672",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\n",
      "['Fraud.csv']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:50:43.935473Z",
     "start_time": "2024-12-19T16:50:43.504374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from daft.daft import connect_start\n",
    "\n",
    "# start Daft Connect (spark-connect compatible server)\n",
    "handle = connect_start(\"sc://0.0.0.0:15003\")\n",
    "\n",
    "# create a Spark Connect client connected to the Daft Connect server\n",
    "spark = SparkSession.builder \\\n",
    "    .remote(f\"sc://localhost:15003\") \\\n",
    "    .appName(\"DaftPySparkExample\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ],
   "id": "bea01f9df90853a1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:50:46.268563Z",
     "start_time": "2024-12-19T16:50:46.216987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = [[2021, \"test\", \"Albany\", \"M\", 42]]\n",
    "columns = [\"Year\", \"First_Name\", \"County\", \"Sex\", \"Count\"]\n",
    "\n",
    "df1 = spark.createDataFrame(data, schema=\"Year int, First_Name STRING, County STRING, Sex STRING, Count int\")\n",
    "df1.show()\n",
    "\n"
   ],
   "id": "da1cb80997b3f915",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewgazelka/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗡️ 🐟 Limit: 00:00 0 rows received, 0 rows emitted\n",
      "🗡️ 🐟 InMemory: 00:00 0 rows emitted\u001B[A\n",
      "╭───────┬──────┬────────┬──────┬───────╮          \n",
      "│ _1    ┆ _2   ┆ _3     ┆ _4   ┆ _5    │\n",
      "│ ---   ┆ ---  ┆ ---    ┆ ---  ┆ ---   │\n",
      "│ Int64 ┆ Utf8 ┆ Utf8   ┆ Utf8 ┆ Int64 │\n",
      "╞═══════╪══════╪════════╪══════╪═══════╡\n",
      "│ 2021  ┆ test ┆ Albany ┆ M    ┆ 42    │\n",
      "╰───────┴──────┴────────┴──────┴───────╯\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:54:00.003220Z",
     "start_time": "2024-12-19T16:53:59.848698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = spark.read.csv(path,\n",
    "                        header=True,\n",
    "                        inferSchema=True,\n",
    "                        sep=\",\")\n",
    "\n",
    "df.show()\n"
   ],
   "id": "d7f471d89dedf29b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring is_streaming: false\n",
      "Ignoring schema: \"\"; not yet implemented\n",
      "Ignoring options: {\"inferSchema\": \"True\", \"header\": \"True\", \"sep\": \",\"}; not yet implemented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗡️ 🐟 Limit: 00:00 0 rows received, 0 rows emitted\n",
      "🗡️ 🐟 ScanTask: 00:00 0 rows emitted\u001B[A\n",
      "╭───────┬──────────┬───────────┬────────────┬────────────────┬─────────┬────────────────╮\n",
      "│ step  ┆ type     ┆ amount    ┆      …     ┆ newbalanceDest ┆ isFraud ┆ isFlaggedFraud │\n",
      "│ ---   ┆ ---      ┆ ---       ┆            ┆ ---            ┆ ---     ┆ ---            │\n",
      "│ Int64 ┆ Utf8     ┆ Float64   ┆ (5 hidden) ┆ Float64        ┆ Int64   ┆ Int64          │\n",
      "╞═══════╪══════════╪═══════════╪════════════╪════════════════╪═════════╪════════════════╡\n",
      "│ 1     ┆ PAYMENT  ┆ 9839.64   ┆ …          ┆ 0              ┆ 0       ┆ 0              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ 1     ┆ PAYMENT  ┆ 1864.28   ┆ …          ┆ 0              ┆ 0       ┆ 0              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ 1     ┆ TRANSFER ┆ 181       ┆ …          ┆ 0              ┆ 1       ┆ 0              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ 1     ┆ CASH_OUT ┆ 181       ┆ …          ┆ 0              ┆ 1       ┆ 0              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ 1     ┆ PAYMENT  ┆ 11668.14  ┆ …          ┆ 0              ┆ 0       ┆ 0              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ …     ┆ …        ┆ …         ┆ …          ┆ …              ┆ …       ┆ …              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ 1     ┆ CASH_OUT ┆ 229133.94 ┆ …          ┆ 51513.44       ┆ 0       ┆ 0              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ 1     ┆ PAYMENT  ┆ 1563.82   ┆ …          ┆ 0              ┆ 0       ┆ 0              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ 1     ┆ PAYMENT  ┆ 1157.86   ┆ …          ┆ 0              ┆ 0       ┆ 0              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ 1     ┆ PAYMENT  ┆ 671.64    ┆ …          ┆ 0              ┆ 0       ┆ 0              │\n",
      "├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
      "│ 1     ┆ TRANSFER ┆ 215310.3  ┆ …          ┆ 0              ┆ 0       ┆ 0              │\n",
      "╰───────┴──────────┴───────────┴────────────┴────────────────┴─────────┴────────────────╯\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T16:54:10.340750Z",
     "start_time": "2024-12-19T16:54:10.205934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rename columns\n",
    "corrected_cols = {'oldbalanceOrg': 'oldBalanceOrig', 'newbalanceOrig': 'newBalanceOrig',\n",
    "                  'oldbalanceDest': 'oldBalanceDest', 'newbalanceDest': 'newBalanceDest'}\n",
    "for old_col, new_col in corrected_cols.items():\n",
    "    df = df.withColumnRenamed(old_col, new_col)\n",
    "\n",
    "df.show()"
   ],
   "id": "52d8765edba4d381",
   "outputs": [
    {
     "ename": "SparkConnectGrpcException",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Error in Daft server: Failed to show string\n\nCaused by:\n    Unsupported relation type: WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(14), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(13), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(12), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(11), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(10), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(9), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(8), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(6), origin: None }), rel_type: Some(Read(Read { is_streaming: false, read_type: Some(DataSource(DataSource { format: Some(\"csv\"), schema: Some(\"\"), options: {\"header\": \"True\", \"sep\": \",\", \"inferSchema\": \"True\"}, paths: [\"/Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\"], predicates: [] })) })) }), rename_columns_map: {\"oldbalanceOrg\": \"oldBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"newbalanceOrig\": \"newBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceDest\": \"oldBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"newbalanceDest\": \"newBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceOrg\": \"oldBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"newbalanceOrig\": \"newBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceDest\": \"oldBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"newbalanceDest\": \"newBalanceDest\"}, renames: [] })\n\nLocation:\n    src/daft-connect/src/translation/logical_plan.rs:132:21\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:15003 {grpc_message:\"Error in Daft server: Failed to show string\\n\\nCaused by:\\n    Unsupported relation type: WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(14), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(13), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(12), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(11), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(10), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(9), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(8), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(6), origin: None }), rel_type: Some(Read(Read { is_streaming: false, read_type: Some(DataSource(DataSource { format: Some(\\\"csv\\\"), schema: Some(\\\"\\\"), options: {\\\"header\\\": \\\"True\\\", \\\"sep\\\": \\\",\\\", \\\"inferSchema\\\": \\\"True\\\"}, paths: [\\\"/Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\\\"], predicates: [] })) })) }), rename_columns_map: {\\\"oldbalanceOrg\\\": \\\"oldBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceOrig\\\": \\\"newBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceDest\\\": \\\"oldBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceDest\\\": \\\"newBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceOrg\\\": \\\"oldBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceOrig\\\": \\\"newBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceDest\\\": \\\"oldBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceDest\\\": \\\"newBalanceDest\\\"}, renames: [] })\\n\\nLocation:\\n    src/daft-connect/src/translation/logical_plan.rs:132:21\", grpc_status:13, created_time:\"2024-12-19T08:54:10.208962-08:00\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mSparkConnectGrpcException\u001B[0m                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m old_col, new_col \u001B[38;5;129;01min\u001B[39;00m corrected_cols\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m      5\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mwithColumnRenamed(old_col, new_col)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/dataframe.py:996\u001B[0m, in \u001B[0;36mDataFrame.show\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[1;32m    995\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshow\u001B[39m(\u001B[38;5;28mself\u001B[39m, n: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m, truncate: Union[\u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, vertical: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 996\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_show_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertical\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/dataframe.py:753\u001B[0m, in \u001B[0;36mDataFrame._show_string\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[1;32m    741\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m    742\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m    743\u001B[0m             error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_BOOL\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    744\u001B[0m             message_parameters\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    747\u001B[0m             },\n\u001B[1;32m    748\u001B[0m         )\n\u001B[1;32m    750\u001B[0m pdf \u001B[38;5;241m=\u001B[39m \u001B[43mDataFrame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithPlan\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    751\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mShowString\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchild\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plan\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_rows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_truncate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertical\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvertical\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    752\u001B[0m \u001B[43m    \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m--> 753\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoPandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m pdf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pdf[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshow_string\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/dataframe.py:1663\u001B[0m, in \u001B[0;36mDataFrame.toPandas\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1661\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot collect on empty session.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1662\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_plan\u001B[38;5;241m.\u001B[39mto_proto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_session\u001B[38;5;241m.\u001B[39mclient)\n\u001B[0;32m-> 1663\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_pandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:873\u001B[0m, in \u001B[0;36mSparkConnectClient.to_pandas\u001B[0;34m(self, plan)\u001B[0m\n\u001B[1;32m    869\u001B[0m (self_destruct_conf,) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_config_with_defaults(\n\u001B[1;32m    870\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspark.sql.execution.arrow.pyspark.selfDestruct.enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfalse\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    871\u001B[0m )\n\u001B[1;32m    872\u001B[0m self_destruct \u001B[38;5;241m=\u001B[39m cast(\u001B[38;5;28mstr\u001B[39m, self_destruct_conf)\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 873\u001B[0m table, schema, metrics, observed_metrics, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_and_fetch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mself_destruct\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_destruct\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m table \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    878\u001B[0m schema \u001B[38;5;241m=\u001B[39m schema \u001B[38;5;129;01mor\u001B[39;00m from_arrow_schema(table\u001B[38;5;241m.\u001B[39mschema, prefer_timestamp_ntz\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1283\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch\u001B[0;34m(self, req, self_destruct)\u001B[0m\n\u001B[1;32m   1280\u001B[0m schema: Optional[StructType] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1281\u001B[0m properties: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m-> 1283\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_and_fetch_as_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mStructType\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1285\u001B[0m \u001B[43m        \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\n",
      "File \u001B[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1264\u001B[0m, in \u001B[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1262\u001B[0m                     \u001B[38;5;28;01myield from\u001B[39;00m handle_response(b)\n\u001B[1;32m   1263\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[0;32m-> 1264\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1503\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_error\u001B[0;34m(self, error)\u001B[0m\n\u001B[1;32m   1490\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1491\u001B[0m \u001B[38;5;124;03mHandle errors that occur during RPC calls.\u001B[39;00m\n\u001B[1;32m   1492\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m \u001B[38;5;124;03mThrows the appropriate internal Python exception.\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, grpc\u001B[38;5;241m.\u001B[39mRpcError):\n\u001B[0;32m-> 1503\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_rpc_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1504\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(error, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1505\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke RPC\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(error):\n",
      "File \u001B[0;32m~/Projects/daft-connect-example/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1543\u001B[0m, in \u001B[0;36mSparkConnectClient._handle_rpc_error\u001B[0;34m(self, rpc_error)\u001B[0m\n\u001B[1;32m   1541\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SparkConnectGrpcException(status\u001B[38;5;241m.\u001B[39mmessage) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1542\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1543\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SparkConnectGrpcException(\u001B[38;5;28mstr\u001B[39m(rpc_error)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mSparkConnectGrpcException\u001B[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Error in Daft server: Failed to show string\n\nCaused by:\n    Unsupported relation type: WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(14), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(13), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(12), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(11), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(10), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(9), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(8), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \"\", plan_id: Some(6), origin: None }), rel_type: Some(Read(Read { is_streaming: false, read_type: Some(DataSource(DataSource { format: Some(\"csv\"), schema: Some(\"\"), options: {\"header\": \"True\", \"sep\": \",\", \"inferSchema\": \"True\"}, paths: [\"/Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\"], predicates: [] })) })) }), rename_columns_map: {\"oldbalanceOrg\": \"oldBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"newbalanceOrig\": \"newBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceDest\": \"oldBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"newbalanceDest\": \"newBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceOrg\": \"oldBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"newbalanceOrig\": \"newBalanceOrig\"}, renames: [] })) }), rename_columns_map: {\"oldbalanceDest\": \"oldBalanceDest\"}, renames: [] })) }), rename_columns_map: {\"newbalanceDest\": \"newBalanceDest\"}, renames: [] })\n\nLocation:\n    src/daft-connect/src/translation/logical_plan.rs:132:21\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:127.0.0.1:15003 {grpc_message:\"Error in Daft server: Failed to show string\\n\\nCaused by:\\n    Unsupported relation type: WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(14), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(13), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(12), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(11), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(10), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(9), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(8), origin: None }), rel_type: Some(WithColumnsRenamed(WithColumnsRenamed { input: Some(Relation { common: Some(RelationCommon { source_info: \\\"\\\", plan_id: Some(6), origin: None }), rel_type: Some(Read(Read { is_streaming: false, read_type: Some(DataSource(DataSource { format: Some(\\\"csv\\\"), schema: Some(\\\"\\\"), options: {\\\"header\\\": \\\"True\\\", \\\"sep\\\": \\\",\\\", \\\"inferSchema\\\": \\\"True\\\"}, paths: [\\\"/Users/andrewgazelka/.cache/kagglehub/datasets/chitwanmanchanda/fraudulent-transactions-data/versions/1\\\"], predicates: [] })) })) }), rename_columns_map: {\\\"oldbalanceOrg\\\": \\\"oldBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceOrig\\\": \\\"newBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceDest\\\": \\\"oldBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceDest\\\": \\\"newBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceOrg\\\": \\\"oldBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceOrig\\\": \\\"newBalanceOrig\\\"}, renames: [] })) }), rename_columns_map: {\\\"oldbalanceDest\\\": \\\"oldBalanceDest\\\"}, renames: [] })) }), rename_columns_map: {\\\"newbalanceDest\\\": \\\"newBalanceDest\\\"}, renames: [] })\\n\\nLocation:\\n    src/daft-connect/src/translation/logical_plan.rs:132:21\", grpc_status:13, created_time:\"2024-12-19T08:54:10.208962-08:00\"}\"\n>"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
